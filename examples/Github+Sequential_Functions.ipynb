{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujvVmMa0btJb",
        "outputId": "df0953ac-8347-4d5b-a448-613dd515acf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.0/457.0 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gofannon (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall git+https://github.com/The-AI-Alliance/gofannon.git --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "# Create an OpenAI client with your deepinfra token and endpoint\n",
        "openai = OpenAI(\n",
        "    api_key=userdata.get('deepinfra'),\n",
        "    base_url=\"https://api.deepinfra.com/v1/openai\",\n",
        ")\n",
        "\n",
        "from gofannon.github import GetRepoContents, CreateIssue\n",
        "from gofannon.basic_math import complex_response\n",
        "\n",
        "\n",
        "tool_list = [F(api_key = userdata.get('github-token')) for F in [GetRepoContents, CreateIssue]]\n",
        "tool_map = {f.name: f.fn for f in tool_list}\n",
        "tool_desc_list = [f.definition for f in tool_list]"
      ],
      "metadata": {
        "id": "JBUKOfaFcSlF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential Actions need to be defined in the user prompt.\n",
        "system_prompt = \"\"\"\n",
        "To analyze code then create issues is a multi step process:\n",
        "Step 1 : Get the code (use get_repo_contents)\n",
        "Step 2 : Analyze the code\n",
        "Step 3 : Create issues (use create_issue here). The body of the issue should be\n",
        "very detailed, specific files should be listed, as well as the block of code that\n",
        "is at the core of the issue. Potential fixes should be sugguested. If the sugguestion\n",
        "is an addition, very clearly elaborate on what should be added. Remember you are\n",
        "creating a single git issue, so meta commentary on the repository is not required.\n",
        "\"\"\"\n",
        "messages = [\n",
        "    { \"role\" : \"system\",\n",
        "     \"content\" : system_prompt\n",
        "     },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"In the repository 'https://github.com/The-AI-Alliance/gofannon/', analyze the code and create issues based on the analysis.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "out = complex_response(prompt=\"In the repository 'https://github.com/The-AI-Alliance/gofannon/', analyze the code and create issues based on the analysis.\",\n",
        "                       system=system_prompt,\n",
        "                       tool_desc_list=tool_desc_list,\n",
        "                       openai_like_client=openai,\n",
        "                       model_name= \"meta-llama/Llama-3.3-70B-Instruct\",\n",
        "                       tool_map=tool_map,\n",
        "                       max_thoughts=5,\n",
        "                       temperature=0.1)\n",
        "\n",
        "print(out['last_response'].choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZpgZbRjUgb_",
        "outputId": "03c07c19-c407-4770-f0a1-849bcb26212f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thinking...\n",
            "thinking...\n",
            "The issue \"Add Usage Examples for gofannon/basic_math/complex.py\" has been created in the repository https://github.com/The-AI-Alliance/gofannon with the issue number #11. \n",
            "\n",
            "Here is the issue:\n",
            "Title: Add Usage Examples for gofannon/basic_math/complex.py\n",
            "Body: The `gofannon/basic_math/complex.py` module is lacking usage examples. It would be helpful to add some examples to demonstrate how to use the `complex_response` function. For instance, an example could be added to show how to use the function with different tool descriptions, tool maps, and OpenAI-like clients.\n",
            "Labels: documentation, enhancement\n"
          ]
        }
      ]
    }
  ]
}